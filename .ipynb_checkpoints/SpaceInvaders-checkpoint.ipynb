{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "import PIL\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hagen.zahn/Projects/spaceInvadersRL\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find a propper resolution in space and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "SPACE_RES = (80,80)\n",
    "TIME_RES = 3\n",
    "\n",
    "def resize(obs):\n",
    "    return np.array(PIL.Image.fromarray(obs).resize(SPACE_RES)) # , PIL.Image.BILINEAR)\n",
    "\n",
    "def sample_steps(action, env, sample_size):\n",
    "    samples = []\n",
    "    info = []\n",
    "    done = False\n",
    "    reward = 0\n",
    "    for i in range(sample_size):\n",
    " \n",
    "        (_, r, d, i) = env.step(action)\n",
    "        samples.append(env.render(mode='rgb_array'))\n",
    "        done = done or d\n",
    "        reward += r\n",
    "        info = i\n",
    "    \n",
    "    obs = np.mean(samples, axis=0).astype('uint8')\n",
    "#    obs = samples[0]\n",
    "    return obs, reward, info, done\n",
    "        \n",
    "\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "obs = resize(env.render(mode='rgb_array'))\n",
    "img = plt.imshow(obs)\n",
    "done = False\n",
    "for i in range(200):\n",
    "    time.sleep(0.01*TIME_RES)\n",
    "    action = env.action_space.sample()\n",
    "    obs, r, _, done = sample_steps(action, env, TIME_RES)\n",
    "    obs = resize(obs)\n",
    "    img.set_data(obs)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define torch value function  cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.feat1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.feat2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(20 * 20 * 64, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 6)\n",
    "        )\n",
    "        self.out = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.feat1(x)\n",
    "        out = self.feat2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.classify(out)\n",
    "        #out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 80, 80])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obs2tensor(obs):\n",
    "    x = torch.FloatTensor(obs)\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    x = x.unsqueeze(0)\n",
    "    x = x.permute(0,3,1,2)\n",
    "    return x\n",
    "net = ValueNet()\n",
    "net(obs2tensor(obs))\n",
    "obs2tensor(obs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define game state Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "MemRow = namedtuple('MemRow', ['action', 'obs', 'reward', 'done', 'next_obs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(memory, batch_size):\n",
    "    samples = min(batch_size, len(memory))\n",
    "    return random.sample(memory, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define QFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_func(value_net, reward, next_obs, discount=0.9):\n",
    "    q = reward + discount * value_net(next_obs)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0849,  1.0755, -0.0771, -0.0307, -0.1578, -0.0482]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_q_values(value_net, observation, next_observations, action, rewards, dones, discount=0.9):\n",
    "    actual_rewards = value_net(observation)\n",
    "    expected_rewards = value_net(next_observations)\n",
    "    best_reward = expected_rewards.max(axis=1)[0]\n",
    "    actual_rewards[:, action] = rewards + discount * best_reward * (1 - dones)\n",
    "    return actual_rewards\n",
    "\n",
    "calculate_q_values(net, obs2tensor(obs), obs2tensor(obs), torch.tensor([1]), torch.tensor([1]), torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debug qfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1472,  1.0327, -0.0338, -0.0799, -0.2048,  0.0085]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_net, observation, next_observations, action, rewards, dones, discount= (net, obs2tensor(obs), obs2tensor(obs), torch.tensor([1]), torch.tensor([1]), torch.tensor([0]), 0.9)\n",
    "actual_rewards = value_net(observation)\n",
    "expected_rewards = value_net(next_observations)\n",
    "best_reward = expected_rewards.max(axis=1)[0]\n",
    "actual_rewards[:, action] = rewards + discount * best_reward * (1 - dones)\n",
    "actual_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "net = ValueNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train value net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2835460901260376"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(model, memory_batch):\n",
    "    observations = torch.cat([obs2tensor(m.obs) for m in memory_batch], dim=0)\n",
    "    next_observations = torch.cat([obs2tensor(m.next_obs) for m in memory_batch], dim=0)\n",
    "    rewards = torch.tensor([m.reward for m in memory_batch])\n",
    "    dones = torch.tensor([1 * m.done for m in memory_batch])\n",
    "    batch_size = len(memory_batch)\n",
    "    actions = torch.tensor([m.action for m in memory_batch])\n",
    "\n",
    "    q_values = calculate_q_values(model, observations, next_observations, actions, rewards, dones)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(observations)\n",
    "    loss = criterion(output, q_values)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    return train_loss\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#net = ValueNet()\n",
    "memory = [MemRow(obs=obs,\n",
    "                 reward=reward,\n",
    "                 done=done,\n",
    "                 next_obs=next_obs,\n",
    "                 action=action)]\n",
    "train_model(net, sample_batch(memory, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## policy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policy(value_net, obs):\n",
    "    return value_net(obs).argmax().item()\n",
    "\n",
    "policy(net, obs2tensor(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image, HTML\n",
    "import base64\n",
    "\n",
    "def plotdesc(fig, text, iwidth=None):\n",
    "    bio = BytesIO()\n",
    "    # save fig as png to bytes IO instead to disk\n",
    "    fig.savefig(bio, format='png')\n",
    "    plt.close(fig)\n",
    "    iwidth = ' width={0} '.format(iwidth) if iwidth is not None else ''\n",
    "    img_tag = \"<img src='data:image/png;base64,\" + base64.b64encode(bio.getvalue()) + \"'{0}/>\".format(iwidth)\n",
    "    datatable = '<table><tr><td>{0}</td><td>{1}</td></tr></table>'.format(img_tag, text)\n",
    "    display(HTML(datatable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "net = ValueNet()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14767387509346008\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "GAMES = 2\n",
    "        \n",
    "memory = []\n",
    "\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "for game in range(GAMES):\n",
    "    game_score = 0\n",
    "    lives = 3\n",
    "    done = False\n",
    "    env.reset()\n",
    "    obs = resize(env.render(mode='rgb_array'))\n",
    "    img = plt.imshow(obs)\n",
    "    while not done:\n",
    "        #time.sleep(0.02*TIME_RES)\n",
    "        if random.random() > 0.9:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = policy(net, obs2tensor(obs))\n",
    "        next_obs, score, info, done = sample_steps(action, env, TIME_RES)\n",
    "        game_score += score\n",
    "        reward = score/200\n",
    "        next_obs = resize(next_obs)\n",
    "        \n",
    "        memory.append(MemRow(obs=obs,\n",
    "                         reward=reward,\n",
    "                         done=done,\n",
    "                         next_obs=next_obs,\n",
    "                         action=action))\n",
    "        if info['ale.lives'] < lives:\n",
    "            lives = info['ale.lives']\n",
    "            reward = -1\n",
    "\n",
    "        img.set_data(obs)\n",
    "        display.display(plt.gcf())\n",
    "        print(loss)\n",
    "        display.clear_output(wait=True)\n",
    "        obs = next_obs\n",
    "        loss = train_model(net, sample_batch(memory, 10))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
